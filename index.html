
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="OccluGaussian">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OccluGaussian</title>

  <link href="./static/css/googlefonts.css" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="./static/js/jquery.3.5.1.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/video_comparison.js" defer></script>
  <!-- <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>         -->
  <script type="text/javascript" async
    src="./static/js/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>        
    
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
  });
  </script>

</head>

<body>

  <section class="hero">
    <div class="hero-body" style="padding-bottom: 0;">>
      <div class="container is-max-desktop" style="min-width: 1200px;">
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <h1 class="title is-1 publication-title">OccluGaussian: Occlusion-Aware Gaussian Splatting for Large Scene Reconstruction and Rendering</h1>
            <br>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <!-- Anonymous Author(s) -->
                <span class="author-block">
                  Shiyong Liu<sup>1*</sup>&nbsp;&nbsp;</span>
                <span class="author-block">
                  Xiao Tang<sup>1*</sup>&nbsp;&nbsp;</span>
                <span class="author-block">
                  Zhihao Li<sup>1*</sup>&nbsp;&nbsp;</span>
                </span>
                <span class="author-block">
                  Yingfan He<sup>2</sup>&nbsp;&nbsp;</span><br />
                </span>
                <span class="author-block">
                  ChongJie Ye<sup>2</sup>&nbsp;&nbsp;</span>
                </span>
                <span class="author-block">
                  Jianzhuang Liu<sup>3</sup>&nbsp;&nbsp;</span>
                </span>
                <span class="author-block">
                  Binxiao Huang<sup>4</sup>&nbsp;&nbsp;</span>
                </span>
                <span class="author-block">
                  Shunbo Zhou<sup>5</sup>&nbsp;&nbsp;</span>
                </span>
                <span class="author-block">
                  Xiaofei Wu<sup>1†</sup>&nbsp;&nbsp;</span>
                </span>
              </span>
            </div>
            <div class="is-size-5 publication-authors" style="font-size: 18px !important;">
              <span class="author-block", style="color:#726f6f"><sup>1</sup>Huawei Noah's Ark Lab&nbsp;&nbsp;&nbsp;&nbsp;</span>
              <span class="author-block", style="color:#726f6f"><sup>2</sup>The Chinese University of HongKong (Shenzhen)&nbsp;&nbsp;&nbsp;&nbsp;</span><br>
              <span class="author-block", style="color:#726f6f"><sup>3</sup>Shenzhen Institute of Advanced Technology</span>
              <span class="author-block", style="color:#726f6f"><sup>4</sup>The University of HongKong&nbsp;&nbsp;&nbsp;&nbsp;</span>
              <span class="author-block", style="color:#726f6f"><sup>5</sup>Huawei Embodied Intelligence Lab&nbsp;&nbsp;&nbsp;&nbsp;</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block", style="font-size: 15px;color:#726f6f">liushiyong3@huawei.com&nbsp;&nbsp;</span>
              <span class="author-block", style="font-size: 15px;color:#726f6f">tangxiao12@huawei.com</span>
              <span class="author-block", style="font-size: 15px;color:#726f6f">zhihao.li@huawei.com&nbsp;&nbsp;</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block", style="font-size: 15px;color:#726f6f"><sup>*&nbsp;</sup>Equal contribution&nbsp;&nbsp;&nbsp;&nbsp;</span>
              <span class="author-block", style="font-size: 15px;color:#726f6f"><sup>†&nbsp;</sup>Corresponding author </span>
            </div>

            <div class="is-size-5 publication-venue">
              <!-- ICCV 2025 submission #7082 -->
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg t="1742180257590" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="8418" width="32" height="32"><path d="M503.073331 412.293591L291.610968 658.981015c-9.408283 10.046702-15.254859 27.664833-9.990701 40.298813a34.474637 34.474637 0 0 0 32.189769 21.336642c7.997041 0 14.549238-2.800084 23.139896-11.435544L598.567405 437.998365a44.599742 44.599742 0 0 0 0.302409-62.878692l-95.796483 37.185119z" fill="#AA142D" p-id="8419"></path><path d="M498.694 407.152637l195.681088-247.527449c10.920329-14.560438 16.083684-22.176667 10.920329-34.575441a37.655533 37.655533 0 0 0-32.805787-23.151096 29.479287 29.479287 0 0 0-22.019863 8.120244L400.310239 375.108472c-19.062974 19.062974-19.029373 43.726116 0.112003 62.867492l349.876129 366.900642a28.661663 28.661663 0 0 0 22.983092 8.736263c14.157226 0 23.330302-8.333051 29.479287-20.642222 5.264158-12.645181-0.560017-25.167157-10.270709-38.282752L498.7164 407.152637" fill="#BDB9B4" p-id="8420"></path><path d="M598.858614 375.108472L257.192332 15.555252S244.647954 0.322794 231.386755 0.009184A33.713015 33.713015 0 0 0 199.622599 20.416198c-5.152155 12.387573-1.456044 21.090235 9.878698 37.319523l293.560834 354.55787 95.796483-37.185119z" fill="#AA142D" p-id="8421"></path><path d="M581.173282 1004.197804a10.987531 10.987531 0 0 1-9.464285-5.499365l-42.606082-70.75253-42.85249 70.75253a10.752324 10.752324 0 0 1-9.486685 5.488165 11.648351 11.648351 0 0 1-9.9683-17.707733l49.583892-79.477592-40.567621-64.995556c-1.075232-1.904057-1.680051-4.032121-1.758453-6.227387a11.648351 11.648351 0 0 1 11.726753-11.446745 10.449914 10.449914 0 0 1 9.464285 5.219357l33.869819 57.054517 33.645813-57.054517a10.046702 10.046702 0 0 1 9.206677-5.219357 11.334741 11.334741 0 0 1 11.715552 11.446745c0 2.161665-0.504015 4.300929-1.500845 6.227387l-40.354814 65.029157 49.079877 79.466392c1.366441 1.792054 2.072062 3.98732 1.99366 6.227387a11.805155 11.805155 0 0 1-11.726753 11.469145zM365.096379 877.085179c5.107354 0 8.501056 3.404902 10.931529 9.486685a14.078824 14.078824 0 0 1 12.880388-9.486685h40.814028a11.144335 11.144335 0 0 1 11.177936 11.177936v21.482247a9.912298 9.912298 0 0 1-11.177936 11.177936 9.990701 9.990701 0 0 1-11.166736-11.177936v-10.30431h-28.91927a6.608199 6.608199 0 0 0-7.280219 7.537826v74.583045h27.440825a11.177936 11.177936 0 1 1 0 22.344672h-72.354177a11.177936 11.177936 0 0 1 0-22.344672h22.579879v-82.120871h-19.9366a11.189137 11.189137 0 0 1 0-22.355873h25.010353zM671.403197 877.073978a9.990701 9.990701 0 0 1 11.177936 11.177937v93.298808h27.698434a11.166736 11.166736 0 1 1 0 22.344672h-78.469561a11.177936 11.177936 0 1 1 0-22.355873h28.426455v-82.109671h-23.408704a11.177936 11.177936 0 0 1 0-22.355873h34.57544z m11.581149-48.318254a16.072484 16.072484 0 1 1-15.960481-15.96048 16.195687 16.195687 0 0 1 15.960481 15.96048zM852.210238 888.251915c0.022401 1.500845-0.224007 2.97929-0.739222 4.379332l-40.802828 104.465543a10.203507 10.203507 0 0 1-10.214707 6.809805h-16.27409a10.125105 10.125105 0 0 1-10.449915-6.809805l-41.295642-104.465543a8.915468 8.915468 0 0 1-0.97443-4.368132 11.200337 11.200337 0 0 1 11.424344-11.177936 10.416313 10.416313 0 0 1 10.192307 7.280219l39.369185 99.122983 38.137147-99.122983a10.427514 10.427514 0 0 1 10.203507-7.280219 11.200337 11.200337 0 0 1 11.424344 11.177936zM263.699728 877.073978a21.325442 21.325442 0 0 1 22.512677 23.039094v103.771123H188.791873a13.193997 13.193997 0 0 1-14.112424-13.518807v-35.729075a22.647082 22.647082 0 0 1 19.197377-22.355873l69.946105-9.800295v-23.050294H186.047791a10.97633 10.97633 0 0 1-11.368342-11.177936 10.864327 10.864327 0 0 1 11.950759-11.177937H263.688527z m0.168005 104.465544v-36.468297l-66.832411 9.31868v27.149617h66.832411z" fill="#000000" p-id="8422"></path></svg>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark" title="Code">
                    <span class="icon" style="padding: 15px;">
                      <svg t="1742179789411" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4887" width="32" height="32"><path d="M512 0C296.192 0 64 65.056 64 208v608C64 958.88 296.192 1024 512 1024c215.776 0 448-65.12 448-208v-608C960 65.056 727.744 0 512 0z m384 816c0 79.488-171.936 144-384 144-212.096 0-384-64.512-384-144v-119.552C194.112 764.576 353.6 800 512 800s317.888-35.424 384-103.552V816z m0-192h-0.128c0 0.32 0.128 0.672 0.128 0.992C896 704 724.064 768 512 768S128 704 128 624.992c0-0.32 0.128-0.672 0.128-0.992H128v-119.552C194.112 572.576 353.6 608 512 608s317.888-35.424 384-103.552V624z m0-192h-0.128c0 0.32 0.128 0.672 0.128 0.992C896 512 724.064 576 512 576S128 512 128 432.992c0-0.32 0.128-0.672 0.128-0.992H128v-109.952C211.872 385.952 365.6 416 512 416s300.128-30.048 384-93.952V432zM512 352C299.904 352 128 287.488 128 208 128 128.448 299.904 64 512 64c212.064 0 384 64.448 384 144 0 79.488-171.936 144-384 144z" fill="#ffffff" p-id="4888"></path><path d="M800 832m-32 0a32 32 0 1 0 64 0 32 32 0 1 0-64 0Z" fill="#ffffff" p-id="4889"></path><path d="M800 640m-32 0a32 32 0 1 0 64 0 32 32 0 1 0-64 0Z" fill="#ffffff" p-id="4890"></path><path d="M800 448m-32 0a32 32 0 1 0 64 0 32 32 0 1 0-64 0Z" fill="#ffffff" p-id="4891"></path></svg>
                    </span>
                    <span>Data [coming soon]</span>
                    </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <div class="tabs-widget">
        <div class="tabs is-centered">
          <ul class="is-marginless">
            <li><a>Gallery</a></li>
            <li><a>Canteen</a></li>
            <li><a>Classbuilding</a></li>
          </ul>
        </div>
        <div class="content has-text-centered is-size-7-mobile">
          <strong>NOTE:</strong> Due to the network speed limit, the videos are compressed with lower quality than the originals.
        </div>
        <div class="tabs-content">
          <!-- Begin gallery. -->
          <div>
            <div class="tabs-widget">
              <div class="tabs-content">
                <div class="video-compare-container">
                  <video class="video" width=100% loop playsinline autoplay muted
                         src="./videos/OccluGaussian_gallery.mp4"></video>
                </div>
              </div>
            </div>
          </div>
          <!-- End gallery. -->
          <!-- Begin canteen. -->
          <div>
            <div class="tabs-widget">
              <div class="tabs-content">
                <div class="video-compare-container">
                  <video class="video" width=100% loop playsinline autoplay muted
                         src="./videos/OccluGaussian_canteen.mp4"></video>
                  <canvas></canvas>
                </div>
              </div>
            </div>
          </div>
          <!-- End canteen. -->
          <!-- Begin classbuilding. -->
          <div>
            <div class="tabs-widget">
              <div class="tabs-content">
                <div class="video-compare-container">
                  <video class="video" width=100% loop playsinline autoplay muted
                         src="./videos/OccluGaussian_classbuilding.mp4"></video>
                  <canvas></canvas>
                </div>
              </div>
            </div>
          </div>
          <!-- End classbuilding. -->          
        </div>
      </div>
    </div>
  </section>
    
    
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <h2 class="title is-3">Abstract</h2>
      <div class="content has-text-justified">
          <p>
            In large-scale scene reconstruction using 3D Gaussian splatting, it is common to partition the scene into multiple smaller regions and reconstruct them individually. However, existing division methods are occlusion-agnostic, meaning that each region may contain areas with severe occlusions. As a result, the cameras within those regions are less correlated, leading to a low average contribution to the overall reconstruction. In this paper, we propose an occlusion-aware scene division strategy that clusters training cameras based on their positions and co-visibilities to acquire multiple regions. Cameras in such regions exhibit stronger correlations and a higher average contribution, facilitating high-quality scene reconstruction. We further propose a region-based rendering technique to accelerate large scene rendering, which culls Gaussians invisible to the region where the viewpoint is located. Such a technique significantly speeds up the rendering without compromising quality. Extensive experiments on multiple large scenes show that our method achieves superior reconstruction results with faster rendering speeds compared to existing state-of-the-art approaches.
          </p>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Overview</h2>
        <img alt="Architecture" src="./static/images/pipeline.jpg" width="100%"/>
    </div>
    
    <div class="container is-max-desktop">
      <div class="content has-text-justified">
        <p>
          <strong>Overview of OccluGaussian.</strong>
          <strong>Top left:</strong> To reconstruct a large scene, we divide it into multiple regions by adopting an occlusionaware scene division strategy. (a) We first create an attributed view graph from the posed cameras, where nodes represent cameras with positional features, and edges represent visibility correlations between them. (b) A graph clustering algorithm is applied to the view graph to cluster the cameras into multiple regions, and (c) we further refine them to obtain more balanced sizes. (d) The region boundaries are calculated based on the clustered cameras. Each region is individually reconstructed and finally merged into a complete model. <strong>Bottom left:</strong> Each region is reconstructed using three sets of training cameras: base cameras located inside the region, extended cameras providing adequate visual content of the region, and border cameras used to constrain Gaussian primitives near the boundaries. <strong>Right:</strong> We introduce a region-based rendering technique, which culls 3D Gaussians that are occluded from the region where the rendering viewpoint is located. Furthermore, we subdivide the scene into smaller sub-regions with fewer essential 3D Gaussians. This approach effectively reduces redundant computations and further boosts our rendering speed.
          </p>
      </div>
    </div>
    
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Comparison With SOTA</h2>
        <img alt="Architecture" src="./static/images/compare_with_sota.jpg" width="100%"/>
        <div>
          <span style="margin-top: 10px; display: flex; align-items: center; justify-content: space-between;">
            <img alt="Architecture" src="./static/images/compare_with_sota_zip-nerf.jpg" width="50%"/>
            <img alt="Architecture" src="./static/images/compare_with_sota_urbanscene3d.jpg" width="40%"/>
          </span>
        </div>
    </div>
  </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Visual comparisons with SOTA</h2>
      <p>
        Here we display side-by-side videos comparing our method to state-of-the-art baselines across different scenes. [<strong>NOTE:</strong> DOGS results is acquired by replacing the scene division strategy proposed in their paper with ours and keep other hyperparameters consistent for 3DGS optimization.] Select a baseline method below:
      </p>
      <br>
        <div class="tabs-widget">
          <div class="tabs is-centered is-toggle is-toggle-rounded is-small">
            <ul class="is-marginless">
              <li><a>CityGaussian vs. Ours</a></li>
              <li><a>VastGaussian vs. Ours</a></li>
              <li><a>DOGS vs. Ours</a></li>
            </ul>
          </div>
          <div class="tabs-content">
            <div class="video-comparison" data-label="Ours" data-label2="CityGaussian">
              <video class="video" width=100% loop playsinline autoplay muted
              src="./videos/Gallery_CityGaussian.mp4"></video>
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/Gallery_CityGaussian_OccluGaussian.mp4"></video>
              <canvas></canvas>
            </div>
            <div class="video-comparison" data-label="Ours" data-label2="VastGaussian">
              <video class="video" width=100% loop playsinline autoplay muted
              src="./videos/Rubble_VastGaussian.mp4"></video>
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/Rubble_OccluGaussian.mp4"></video>
              <canvas></canvas>
            </div>
            <div class="video-comparison" data-label="Ours" data-label2="DOGS">
              <video class="video" width=100% loop playsinline autoplay muted
              src="./videos/Berlin_DOGS.mp4"></video>
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/Berlin_OccluGaussian.mp4"></video>
              <canvas></canvas>
            </div>
          </div>
        </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Visual comparisons with Clustering Methods</h2>
      <p>
        Here, we present side-by-side videos that conduct a comprehensive comparison between our method and various clustering methods in diverse scenes. Please choose a clustering method from the options below:
      </p>
      <br>
        <div class="tabs-widget">
          <div class="tabs is-centered is-toggle is-toggle-rounded is-small">
            <ul class="is-marginless">
              <li><a>Metis vs. Ours</a></li>
              <li><a>Kmeans vs. Ours</a></li>
            </ul>
          </div>
          <div class="tabs-content">
            <div class="video-comparison" data-label="Ours" data-label2="Metis">
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/Gallery_Metis.mp4"></video>
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/Gallery_Metis_OccluGaussian.mp4"></video>
              <canvas></canvas>
            </div>
            <div class="video-comparison" data-label="Ours" data-label2="Kmeans">
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/Classbuilding_Kmeans.mp4"></video>
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/Classbuilding_OccluGaussian.mp4"></video>
              <canvas></canvas>
            </div>
          </div>
        </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Ablation Study of Region-Based Rendering</h2>
      <p>
        We selected a view from the Alameda scene in the Zip-NeRF dataset for rendering. Then, we printed the real-time frames per second (FPS) of the rendering above the video. This is to demonstrate that our region-based rendering method incurs no loss in visual quality during the process of rendering acceleration. Here, 'RBR' denotes the vanilla region-based rendering approach, and 'RSD' denotes the region subdivision approach within our region-based rendering framework.
        <br><br>Our region-based culling strategy significantly boosts the rendering speed without causing any noticeable decline in visual quality. Furthermore, the proposed region subdivision technique can further expedite the rendering process.
      </p>
      <br>
        <div class="tabs-widget">
          <div class="tabs is-centered is-toggle is-toggle-rounded is-small">
            <ul class="is-marginless">
              <li><a>Full vs. w/o RBR & RSD</a></li>
              <li><a>Full vs. w/o RSD</a></li>
            </ul>
          </div>
          <div class="tabs-content">
            <div class="video-comparison" data-label="Ours" data-label2="RBR_RSD">
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/London_RBR_full.mp4"></video>
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/London_RBR.mp4"></video>
              <canvas></canvas>
            </div>
            <div class="video-comparison" data-label="Ours" data-label2="RSD">
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/London_RSD_full.mp4"></video>
              <video class="video" width=100% loop playsinline autoplay muted
                      src="./videos/London_RSD.mp4"></video>
              <canvas></canvas>
            </div>
          </div>
        </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre>
        <code>
@article{liu2025occlugaussian,
    title     = {OccluGaussian: Occlusion-Aware Gaussian Splatting for Large Scene Reconstruction and Rendering},
    author    = {Liu, Shiyong and Tang, Xiao and Li, Zhihao and He, Yingfan and Ye, Chongjie and Liu, Jianzhuang and Huang, Binxiao and Zhou, Shunbo and Wu, Xiaofei},
    booktitle = {arXiv.org},
    year      = {2025}
}
        </code>
      </pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
                This webpage is based on the project page for <a href="https://camp-nerf.github.io">CamP</a>. The video comparison tool is from the <a
                href="https://dorverbin.github.io/refnerf/index.html">Ref-NeRF</a> project.</p>
          </div>
        </div>
      </div>
    </div>
  </footer>
      
      
</body>

</html>
